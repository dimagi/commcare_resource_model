estimation_buffer: 0.5
estimation_growth_factor: 0.01  # buffer increases by 1% per month
storage_buffer: 0.33  # keep max storage at 75% of disk
storage_display_unit: TB

summary_dates:
  - '2020-12'

vm_os_storage_gb: 50
vm_os_storage_group: 'VM_os'

usage:
  users:
    model: 'date_range_value'
    ranges:
      - ['20201101', '20201201', 1132]

  #Number of forms per user per month
  forms_monthly:
    model: 'derived_factor'
    dependant_field: 'users'
    factor: 14134 # Forms per user per month (16000000 forms / 1132 users)

  # Total Forms ever created
  forms_total:
    model: 'cumulative'
    dependant_field: 'forms_monthly'
    start_with: 16000000   # from ES form index (total docs)

  forms_per_sec_max:
    model: 'derived_factor'
      dependant_field: 'users'
      factor: 0.0025  # 2 forms per second for 755 users

  restores_per_second:
    model: 'derived_factor'
    dependant_field: 'users'
    factor: 0.00003  # 0.03 restores per second for 755 users

  #Number of cases per user per month
  cases_total:
    model: 'baseline_with_growth'
    dependant_field: 'users'
    baseline: 0
    monthly_growth: 0
    start_with: 19000000

  # Number of cases updated per user per month
  case_transactions:
    model: 'derived_factor'
    dependant_field: 'forms_monthly'
    factor: 3  # 3 cases per form
  # Total Case Transaction
  case_transactions_total:
    model: 'cumulative'
    dependant_field: 'case_transactions'
    start_with: 1900000000   # 10 per case?

services:
  pg_shards:
    static_number: 1
    include_ha_resources: True
    storage:
      group: 'SSD'
      data_models:
        - referenced_field: 'forms_total'
          unit_size: 1200
        - referenced_field: 'cases_total'
          unit_size: 1800
    process:
      cores_per_node: 2
      ram_per_node: 8

  pg_proxy:
    static_number: 1
    usage_capacity_per_node: 150000
    storage_scales_with_nodes: True
    storage:
      group: 'VM_other'
      static_baseline: 200GB
      override_storage_buffer: 0
      override_estimation_buffer: 0
    process:
      cores_per_node: 2
      ram_per_node: 8

  pg_main:
    usage_capacity_per_node: 150000
    storage_scales_with_nodes: True
    static_number: 1
    storage:
      group: 'SSD'
      static_baseline: 250GB  # to account for other static tables
      data_models:
        - referenced_field: 'users'
          unit_size: 1600
    process:
      cores_per_node: 4
      ram_per_node: 16

  couchdb:
    usage_capacity_per_node: 50000
    min_nodes: 3
    storage:
      group: 'SSD'
      redundancy_factor: 3
      static_baseline: 50GB  # to account for other databases
      override_storage_buffer: 0.8  # space for compaction
      data_models:
        - referenced_field: 'users'
          unit_size: 600000   # disk size / doc count of icds @ 2017-12-13
    process:
      cores_per_node: 4
      ram_per_node: 8

  es_datanode:
    usage_capacity_per_node: 15000
    min_nodes: 1
    storage:
      group: 'SAS'
      redundancy_factor: 2
      data_models:
        - referenced_field: 'forms_total'
          unit_size: 5500
        - referenced_field: 'cases_total'
          unit_size: 1800
    process:
      cores_per_node: 8
      ram_per_node: 32

  riakcs:
    usage_capacity_per_node: 50000
    # avg attachment size of 12560 bytes (11000*0.96 + 50000*0.04)
    # RAM requirement per key = 130b
    # num keys = 10TB / (12560b x 3<redundancy factor>)
    # RAM needed = 130b x num keys = 35GB (64GB avail per node)
    max_storage_per_node: 25TB
    min_nodes: 5
    storage:
      group: 'SSD'
      redundancy_factor: 3
      static_baseline: 10TB  # to account for exports etc
      data_models:
        - referenced_field: 'forms_total'  # 96% of objects
          unit_size: 11000
    process:
      # current load quite low (~15%) (2018-10-11)
      cores_per_node: 4
      # need to be able to fit all keys in RAM since we're using bitcask backend
      # Current usage is at 30% (2018-10-11)
      ram_per_node: 4
      ram_model:
      - referenced_field: 'forms_total'
        # key size (45 + 6 + 79) (overhead + bucket + key)
        # bucket = 'blobdb'
        # new keys are smaller but stick with old key length for safety:
        #   new: form/xxxxxxxxxxxxxxuuidxxxxxxxxxxxxxx/Xpi-XM9CZvQ
        #   old: form/xxxxxxxxxxxxxxuuidxxxxxxxxxxxxxx/form.xml.xxxxxxxxxxxxxxuuidxxxxxxxxxxxxxx
        unit_size: 130
      ram_redundancy_factor: 3
      ram_static_baseline: 1  # per node

  pg_ucr:
    usage_capacity_per_node: 100000
    storage_scales_with_nodes: True
    min_nodes: 1
    storage:
      # This is a rough estimate.
      # The person case UCR is 35% of total UCR usage.
      group: 'SSD'
      data_models:
        - referenced_field: 'cases_total'  # cumulative
          unit_size: 4000  # to account for monthly data etc.
    process:
      cores_per_node: 4
      ram_per_node: 16

  pg_warehouse:
    usage_capacity_per_node: 300000
    storage_scales_with_nodes: True
    storage:
      group: 'SSD'
      data_models:
        - referenced_field: 'forms_total'
          unit_size: 4000  # to account for monthly data etc.
    process:
      cores_per_node: 4
      ram_per_node: 16

  pillowtop:
    static_number: 1
    storage:
      group: 'VM_other'
      static_baseline: 100GB
      override_storage_buffer: 0
      override_estimation_buffer: 0
    process:
      cores_per_node: 8
      ram_per_node: 64

  celery:
    storage_scales_with_nodes: True
    process:
      cores_per_node: 8
      ram_per_node: 32
      cores_per_sub_process: 0.7  # reduced from 1 since we use django VMs as well
      ram_per_sub_process: 0.5  # reduced from 0.7 since we use django VMs as well
      sub_processes:
        - name: 'reminder_case_update_queue'
          capacity: 1000
        - name: 'reminder_queue'
          capacity: 30000
        - name: 'ucr_indicator_queue'
          capacity: 5000
        - name: 'sms_queue'
          capacity: 15000
        - name: 'case_rule_queue'
          capacity: 60000
        - name: 'reminder_rule_queue'
          capacity: 60000
        - name: 'submission_reprocessing_queue'
          capacity: 60000
    storage:
      group: 'VM_other'
      static_baseline: 100GB
      override_storage_buffer: 0
      override_estimation_buffer: 0

  django:
    usage_capacity_per_node: 15000
    storage_scales_with_nodes: True
    process:
      cores_per_node: 4
      ram_per_node: 8
    storage:
      group: 'VM_other'
      static_baseline: 100GB
      override_storage_buffer: 0
      override_estimation_buffer: 0

  redis:
    # usage_capacity_per_node: 200000
    static_number: 1
    process:
      cores_per_node: 2
      ram_per_node: 16
      ram_model:
        - referenced_field: 'users'
          unit_size: 50KB
      ram_static_baseline: 33  # per node (assume only 50% ram is usable)
    storage:
      group: 'SAS'
      data_models:
        - referenced_field: 'users'
          unit_size: 50KB

  nginx:  # limits for nginx not clear
    usage_capacity_per_node: 250000
    storage_scales_with_nodes: True
    static_number: 1
    process:
      cores_per_node: 2
      ram_per_node: 4
    storage:
      group: 'VM_other'
      static_baseline: 250GB  # logs etc
      override_storage_buffer: 0
      override_estimation_buffer: 0

  rabbitmq:  # limits for rabbitmq not clear
    static_number: 1
    storage_scales_with_nodes: True
    process:
      cores_per_node: 2
      ram_per_node: 8
    storage:  # don't have a model for rabbitmq storage
      group: 'SAS'
      static_baseline: 500GB
      override_storage_buffer: 0
      override_estimation_buffer: 0
